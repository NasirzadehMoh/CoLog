{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup CoLog\n",
    "\n",
    "CoLog can be set up in two ways: **Local Setup** or **Online Setup (Google Colab)**.\n",
    "\n",
    "---\n",
    "\n",
    "### Option 1: Local Setup\n",
    "\n",
    "If you already have CoLog cloned on your local machine:\n",
    "\n",
    "1. **Navigate to your CoLog directory** (e.g., `C:\\Users\\user\\Documents\\GitHub\\colog`)\n",
    "2. **No need to run `git clone`** — you're already working in the repository\n",
    "3. **Install dependencies** using your local Python environment:\n",
    "   ```bash\n",
    "   python -m pip install -r requirements.txt\n",
    "   ```\n",
    "4. **Ensure Python environment is configured** in VS Code (select your Python interpreter)\n",
    "5. **Start working** with the existing dataset and groundtruth folders\n",
    "\n",
    "**Advantages:**\n",
    "- Faster access to files and datasets\n",
    "- Better control over environment and dependencies\n",
    "- Can use local GPU/CPU resources\n",
    "- All changes are immediately saved to your local repository\n",
    "\n",
    "---\n",
    "\n",
    "### Option 2: Online Setup (Google Colab)\n",
    "\n",
    "If you want to run CoLog in Google Colab or need a fresh clone:\n",
    "\n",
    "1. **Clone the repository** from GitHub:\n",
    "   ```bash\n",
    "   !git clone https://github.com/NasirzadehMoh/CoLog.git\n",
    "   ```\n",
    "2. **Change directory** to the cloned folder:\n",
    "   ```bash\n",
    "   %cd CoLog\n",
    "   ```\n",
    "3. **Install dependencies** using Colab's Python environment:\n",
    "   ```bash\n",
    "   !pip install -r requirements.txt\n",
    "   ```\n",
    "4. **Upload or unrar datasets** if needed (or download them programmatically)\n",
    "5. **Run preprocessing and training** using the provided scripts\n",
    "\n",
    "**Advantages:**\n",
    "- Free GPU access (Tesla T4/K80)\n",
    "- No local setup required\n",
    "- Easy sharing and collaboration\n",
    "- Isolated environment for experiments\n",
    "\n",
    "---\n",
    "\n",
    "### For This Notebook\n",
    "\n",
    "**We use the Online Setup (Google Colab Pro)** to take advantage of GPU resources and cloud-based execution. The cells below will clone the repository, install dependencies, and setup the environment in Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/NasirzadehMoh/CoLog.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TDIREtaPxq-t"
   },
   "source": [
    "### Install Requirements\n",
    "\n",
    "This step installs all Python dependencies required to run CoLog, including:\n",
    "\n",
    "**Core Dependencies:**\n",
    "- **PyTorch** - Deep learning framework for model training\n",
    "- **Transformers** - Hugging Face library for transformer models\n",
    "- **SentenceTransformers** - For generating log message embeddings\n",
    "- **scikit-learn** - Machine learning utilities and metrics\n",
    "- **imbalanced-learn** - Tools for handling class imbalance (Tomek Links, SMOTE, etc.)\n",
    "- **NumPy & Pandas** - Data manipulation and numerical operations\n",
    "- **tqdm** - Progress bars for long-running operations\n",
    "\n",
    "**Additional Libraries:**\n",
    "- **TensorBoard** - Visualization for training metrics and hyperparameter tuning\n",
    "- **spaCy** - NLP library for NER-based log parsing\n",
    "- Various parser dependencies (Drain, etc.)\n",
    "\n",
    "---\n",
    "\n",
    "**Installation Options:**\n",
    "\n",
    "#### For Google Colab (Online Setup):\n",
    "```bash\n",
    "!pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "#### For Local Environment:\n",
    "```bash\n",
    "python -m pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "#### For Virtual Environment (Recommended for Local):\n",
    "```bash\n",
    "# Create virtual environment first\n",
    "python -m venv venv\n",
    "# Activate it (Windows)\n",
    ".\\venv\\Scripts\\activate\n",
    "# Or on Linux/Mac\n",
    "source venv/bin/activate\n",
    "# Then install\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**Expected Installation Time:**\n",
    "- ~5-10 minutes depending on internet speed and whether PyTorch needs to be downloaded\n",
    "- Colab environments are faster due to pre-installed packages\n",
    "\n",
    "**GPU Support:**\n",
    "- If you have CUDA-enabled GPU, PyTorch will be installed with CUDA support\n",
    "- Use `--device cuda` in subsequent commands to leverage GPU acceleration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JqMrF1JbXN30"
   },
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mVeXlx7LxvF-"
   },
   "source": [
    "### Change to CoLog Directory\n",
    "\n",
    "After cloning the repository, we need to navigate into the CoLog directory to access all scripts and datasets.\n",
    "\n",
    "---\n",
    "\n",
    "**Why this is necessary:**\n",
    "- All relative file paths in the scripts assume you're working from the CoLog root directory\n",
    "- The `groundtruth/`, `datasets/`, `neuralnetwork/`, and other folders are located here\n",
    "- Running scripts without being in the correct directory will cause \"file not found\" errors\n",
    "\n",
    "---\n",
    "\n",
    "**For Google Colab (Online Setup):**\n",
    "\n",
    "The default working directory in Colab is `/content/`. After cloning, CoLog will be at `/content/CoLog/`.\n",
    "\n",
    "```python\n",
    "%cd /content/CoLog\n",
    "```\n",
    "\n",
    "The `%cd` magic command changes the current working directory for all subsequent cells.\n",
    "\n",
    "---\n",
    "\n",
    "**For Local Setup:**\n",
    "\n",
    "If you're running locally (not in Colab), you would navigate to your local CoLog path:\n",
    "\n",
    "```python\n",
    "# Example for Windows\n",
    "%cd C:/Users/user/Documents/GitHub/CoLog\n",
    "\n",
    "# Example for Linux/Mac\n",
    "%cd ~/Documents/CoLog\n",
    "```\n",
    "\n",
    "Or you can skip this if you opened the notebook from within the CoLog directory already.\n",
    "\n",
    "---\n",
    "\n",
    "**Verification:**\n",
    "\n",
    "After running the next cell, you should see output like:\n",
    "```\n",
    "/content/CoLog\n",
    "```\n",
    "\n",
    "You can verify you're in the right place by listing files:\n",
    "```python\n",
    "!ls -la  # Linux/Mac/Colab\n",
    "!dir     # Windows\n",
    "```\n",
    "\n",
    "You should see folders like `groundtruth/`, `datasets/`, `neuralnetwork/`, `transformer/`, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ffS7uRZshAI1"
   },
   "outputs": [],
   "source": [
    "%cd /content/CoLog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8X4B2D1Basbd"
   },
   "source": [
    "### Extract Ground Truth (All-in-One Pipeline)\n",
    "\n",
    "This section demonstrates how to run `groundtruth/main.py` - an integrated pipeline that combines **preprocessing**, **ground truth extraction**, and **class imbalance resampling** in a single command.\n",
    "\n",
    "---\n",
    "\n",
    "**What it does (3 steps in one):**\n",
    "\n",
    "1. **Preprocessing (Automatic):**\n",
    "   - Parses raw logs using either Drain (rule-based) or NER-based parser\n",
    "   - Extracts unique log messages across all parsed logs\n",
    "   - Generates embeddings using SentenceTransformers and saves them as pickle files\n",
    "\n",
    "2. **Ground Truth Extraction:**\n",
    "   - Reads parsed logs (CSV from Drain or pickle files from NER parser)\n",
    "   - Constructs sequences for each log message using a configurable sliding window\n",
    "   - Assigns labels (normal/anomaly) based on dataset-specific labeling strategies\n",
    "   - Splits data into train/validation/test sets and saves ground truth files\n",
    "\n",
    "3. **Class Imbalance Resampling (Optional):**\n",
    "   - Applies resampling techniques (e.g., Tomek Links, RandomUnderSampler) when `--resample` flag is used\n",
    "   - Balances the training data to improve model performance\n",
    "   - Creates resampled datasets in subdirectories\n",
    "\n",
    "---\n",
    "\n",
    "**Key Concepts:**\n",
    "\n",
    "- **sequence_type**: \n",
    "  - `background`: Uses current message + previous messages as context `[prev_msg, current_msg]`\n",
    "  - `context`: Uses previous + current + following messages `[prev_msg, current_msg, next_msg]`\n",
    "  \n",
    "- **window_size**: Number of messages on each side (left/right) of the current message\n",
    "  - Example: `window_size=1` with `context` type → `[msg_{i-1}, msg_i, msg_{i+1}]`\n",
    "\n",
    "- **Labeling Strategies** (automatic based on dataset):\n",
    "  - Type 1 (hadoop, zookeeper): Level column-based labeling\n",
    "  - Type 2 (spark, windows): Wordlist heuristic\n",
    "  - Type 3 (bgl): Label '-' indicates normal\n",
    "  - Type 4 (casper-rw, dfrws*, honeynet*): NER parser stored pickle\n",
    "\n",
    "---\n",
    "\n",
    "**Available Command-Line Arguments:**\n",
    "\n",
    "| Argument | Type | Default | Description |\n",
    "|----------|------|---------|-------------|\n",
    "| `--dataset` | str | `hadoop` | Dataset name to process (choices: hadoop, spark, bgl, windows, zookeeper, casper-rw, etc.) |\n",
    "| `--dataset-dir` | str | `datasets/` | Path to the root datasets directory |\n",
    "| `--sequence-type` | str | `context` | Sequence type: `background` or `context` |\n",
    "| `--window-size` | int | `1` | Number of messages on each side of current message |\n",
    "| `--train-ratio` | float | `0.6` | Fraction of non-test data for training |\n",
    "| `--valid-ratio` | float | `0.2` | Fraction of non-test data for validation |\n",
    "| `--model` | str | `all-MiniLM-L6-v2` | SentenceTransformer model for embeddings |\n",
    "| `--batch-size` | int | `64` | Batch size for embeddings computation |\n",
    "| `--device` | str | `auto` | Device for processing: `auto`, `cpu`, or `cuda` |\n",
    "| `--force` | flag | False | Force re-processing even if files exist |\n",
    "| `--verbose` | flag | False | Enable detailed debug-level logging |\n",
    "| `--groundbreaking` | flag | False | Enable multi-label/sequence-level labeling |\n",
    "| `--resample` | flag | False | Automatically run resampling after extraction |\n",
    "| `--resample-method` | str | None | Resampling method (e.g., `TomekLinks`, `RandomUnderSampler`, `SMOTE`) |\n",
    "| `--random-seed` | int | `100` | Random seed for reproducibility |\n",
    "| `--dry-run` | flag | False | Preview what would be done without actually processing files |\n",
    "\n",
    "---\n",
    "\n",
    "**Output Files:**\n",
    "\n",
    "Saved in `datasets/<dataset>/groundtruth/<sequence_type>_<window_size>/`:\n",
    "\n",
    "**Basic Ground Truth Files:**\n",
    "- `messages.p`: Message ID → tokenized message (NumPy array)\n",
    "- `sequences.p`: Message ID → list of surrounding messages ('UNK' for padding)\n",
    "- `labels.p`: Message ID → label integer (0=normal, 1=anomaly)\n",
    "- `keys.p`: Ordered list of all message IDs\n",
    "- `train_set.p`, `valid_set.p`, `test_set.p`: Split datasets for model training\n",
    "\n",
    "**Resampled Files** (if `--resample` used):\n",
    "- Saved in `resampled_groundtruth/<method>/` subdirectory\n",
    "- Same structure as above but with balanced class distributions\n",
    "\n",
    "---\n",
    "\n",
    "**Usage Examples:**\n",
    "\n",
    "```bash\n",
    "# Basic usage - preprocessing + ground truth extraction only\n",
    "!python groundtruth/main.py --dataset hadoop --sequence-type context --window-size 1\n",
    "\n",
    "# With all three steps (preprocessing + extraction + resampling)\n",
    "!python groundtruth/main.py --dataset spark \\\n",
    "    --sequence-type context --window-size 1 \\\n",
    "    --model all-MiniLM-L6-v2 --batch-size 128 --device auto \\\n",
    "    --resample --resample-method TomekLinks \\\n",
    "    --verbose\n",
    "\n",
    "# Force regeneration with GPU acceleration\n",
    "!python groundtruth/main.py --dataset bgl \\\n",
    "    --sequence-type background --window-size 2 \\\n",
    "    --batch-size 256 --device cuda \\\n",
    "    --force --verbose\n",
    "\n",
    "# Custom train/valid split ratios with resampling\n",
    "!python groundtruth/main.py --dataset windows \\\n",
    "    --train-ratio 0.7 --valid-ratio 0.15 \\\n",
    "    --resample --resample-method RandomUnderSampler\n",
    "\n",
    "# Dry run to preview without processing\n",
    "!python groundtruth/main.py --dataset zookeeper \\\n",
    "    --sequence-type context --window-size 1 \\\n",
    "    --resample --resample-method SMOTE \\\n",
    "    --dry-run\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**Advantages of Unified Pipeline:**\n",
    "\n",
    "✓ **Simplified workflow** - One command instead of three separate scripts  \n",
    "✓ **Automatic preprocessing** - No need to run preprocessing separately  \n",
    "✓ **Consistent parameters** - Same settings used across all steps  \n",
    "✓ **Efficient execution** - Embeddings computed once and reused  \n",
    "✓ **Reproducible** - Single random seed for all randomized operations  \n",
    "\n",
    "---\n",
    "\n",
    "**Note:** The script automatically detects which parser (Drain vs NER) to use based on the dataset type, so you don't need to worry about parser selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Complete pipeline with preprocessing, extraction, and resampling\n",
    "!python groundtruth/main.py \\\n",
    "    --dataset hadoop \\\n",
    "    --sequence-type context \\\n",
    "    --window-size 1 \\\n",
    "    --model all-MiniLM-L6-v2 \\\n",
    "    --batch-size 128 \\\n",
    "    --device auto \\\n",
    "    --resample \\\n",
    "    --resample-method TomekLinks \\\n",
    "    --verbose\n",
    "\n",
    "# Other datasets (uncomment to run):\n",
    "# !python groundtruth/main.py --dataset spark --sequence-type context --window-size 1 --resample --resample-method TomekLinks --verbose\n",
    "# !python groundtruth/main.py --dataset zookeeper --sequence-type context --window-size 1 --resample --resample-method TomekLinks --verbose\n",
    "# !python groundtruth/main.py --dataset bgl --sequence-type context --window-size 1 --resample --resample-method TomekLinks --verbose\n",
    "# !python groundtruth/main.py --dataset windows --sequence-type context --window-size 1 --resample --resample-method RandomUnderSampler --verbose\n",
    "# !python groundtruth/main.py --dataset casper-rw --sequence-type context --window-size 1 --resample --resample-method TomekLinks --verbose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JrYZcI-KXewb"
   },
   "source": [
    "### Train CoLog\n",
    "\n",
    "After extracting ground truth data, we can now train the CoLog model using the prepared dataset. The training script handles the entire neural network training process.\n",
    "\n",
    "---\n",
    "\n",
    "**Why this is necessary:**\n",
    "- Trains the collaborative transformer model on your processed log sequences\n",
    "- Learns patterns from normal and anomalous log sequences\n",
    "- Creates model checkpoints that can be used for anomaly detection\n",
    "- Automatically handles train/validation splits and optimization\n",
    "\n",
    "---\n",
    "\n",
    "**Available Command-Line Arguments:**\n",
    "\n",
    "| Argument | Type | Default | Description |\n",
    "|----------|------|---------|-------------|\n",
    "| **Dataset Arguments** |\n",
    "| `--dataset` | str | `hadoop` | Dataset to train on (choices: hadoop, spark, bgl, windows, zookeeper, casper-rw, etc.) |\n",
    "| `--sequence-type` | str | auto-detect | Sequence construction type: `background` or `context` |\n",
    "| `--window-size` | int | auto-detect | Number of messages on each side of current message in sequences |\n",
    "| **Training Configuration** |\n",
    "| `--name` | str | `CoLog` | Name identifier for this training run (used for organizing outputs) |\n",
    "| `--batch-size` | int | `32` | Number of samples processed before model update |\n",
    "| `--max-epoch` | int | `100` | Maximum number of training epochs |\n",
    "| `--warmup-epoch` | float | `5` | Warmup epochs with gradually increasing learning rate |\n",
    "| `--early-stop` | int | `10` | Early stopping patience (epochs without improvement) |\n",
    "| `--evaluation-start` | int | `0` | Epoch to start evaluation after |\n",
    "| `--random-seed` | int | random | Random seed for reproducibility |\n",
    "| `--device` | str | `auto` | Device for training: `cpu`, `cuda`, or `auto` |\n",
    "| `--output` | str | `runs/` | Path to output results directory |\n",
    "| `--train-ratio` | float | auto-detect | Fraction of dataset for training |\n",
    "| **Optimizer Arguments** |\n",
    "| `--optimizer` | str | `adam` | Optimizer function name |\n",
    "| `--optimizer-params` | str | `{\"weight_decay\": 0}` | Optimizer parameters as string dict |\n",
    "| `--learning-rate` | float | `0.001` | Initial learning rate |\n",
    "| `--lr-decay` | float | `0.1` | Learning rate decay coefficient |\n",
    "| `--decay-times` | int | `3` | Number of learning rate reductions |\n",
    "| `--grad-clip` | float | `5.0` | Gradient clipping max norm; -1 disables clipping |\n",
    "| **Model Architecture** |\n",
    "| `--embedding-size` | int | `300` | Dimension of word embeddings (input to message adapter LSTM) |\n",
    "| `--sequences-fsize` | int | `384` | Dimension of sequence features (input to sequence adapter) |\n",
    "| `--layers` | int | `2` | Number of collaborative transformer layers |\n",
    "| `--heads` | int | `8` | Number of attention heads in collaborative transformer |\n",
    "| `--hidden-size` | int | `256` | Size of collaborative transformer hidden layers |\n",
    "| `--dropout-rate` | float | `0.1` | Dropout probability for regularization |\n",
    "| `--projection-size` | int | `128` | Size of projection layer for modality fusion |\n",
    "| **Data Processing** |\n",
    "| `--len-messages` | int | `50` | Maximum length of log messages (tokens) |\n",
    "| `--len-sequences` | int | `50` | Maximum length of log sequences |\n",
    "| **Class Imbalance** |\n",
    "| `--resample-method` | str | `Original` | Method for handling class imbalance (TomekLinks, RandomUnderSampler, SMOTE, etc.) |\n",
    "| `--groundbreaking` | flag | False | Enable groundbreaking mode with 4 classes instead of 2 |\n",
    "| **Hyperparameter Tuning** |\n",
    "| `--tuning` | flag | False | Enable hyperparameter tuning mode using Ray Tune |\n",
    "| `--train-bmodel` | flag | False | Train with best configuration after tuning (only with `--tuning`) |\n",
    "| `--tuner-samples` | int | `10` | Number of tuning configurations to sample |\n",
    "\n",
    "---\n",
    "\n",
    "**How Training Works:**\n",
    "\n",
    "1. **Loads Prepared Data**: Reads the ground truth data from `datasets/<dataset>/groundtruth/<sequence_type>_<window_size>/`\n",
    "2. **Initializes Model**: Creates the collaborative transformer architecture with specified hyperparameters\n",
    "3. **Training Loop**: Runs for specified epochs, optimizing on the training set with backpropagation\n",
    "4. **Validation**: Periodically evaluates on validation set to prevent overfitting\n",
    "5. **Checkpointing**: Saves best models to `runs/<name>/models/`\n",
    "6. **Logging**: Records training metrics to `runs/<name>/logs/` for TensorBoard visualization\n",
    "\n",
    "---\n",
    "\n",
    "**Output Location:**\n",
    "\n",
    "After training, you'll find:\n",
    "- Model checkpoints: `runs/<dataset_name>/models/best<seed>.pkl`\n",
    "- Training logs: `runs/<dataset_name>/logs/` (TensorBoard events)\n",
    "- Configuration file: `runs/<dataset_name>/<name>_config.json`\n",
    "\n",
    "---\n",
    "\n",
    "**Training Tips:**\n",
    "\n",
    "- Start with `--max-epoch 20` for initial experiments\n",
    "- Increase epochs if validation loss is still decreasing\n",
    "- Monitor training progress in the output logs\n",
    "- GPU/CUDA will be used automatically if available (much faster than CPU)\n",
    "- Use `--early-stop` to prevent overfitting and save time\n",
    "- For hyperparameter tuning, use `--tuning --tuner-samples 20` to search optimal configuration\n",
    "\n",
    "---\n",
    "\n",
    "**Usage Examples:**\n",
    "\n",
    "```bash\n",
    "# Basic training with default parameters\n",
    "!python train.py --name hadoop --dataset hadoop --max-epoch 20\n",
    "\n",
    "# Training with custom hyperparameters\n",
    "!python train.py --name spark_custom --dataset spark \\\n",
    "    --batch-size 64 --learning-rate 0.0005 --max-epoch 50 \\\n",
    "    --layers 3 --heads 12 --hidden-size 512\n",
    "\n",
    "# Training with resampled data for imbalanced datasets\n",
    "!python train.py --name windows_balanced --dataset windows \\\n",
    "    --resample-method RandomUnderSampler --max-epoch 30\n",
    "\n",
    "# Hyperparameter tuning mode\n",
    "!python train.py --name bgl_tuned --dataset bgl \\\n",
    "    --tuning --tuner-samples 20 --train-bmodel\n",
    "\n",
    "# Training with specific device and random seed\n",
    "!python train.py --name zookeeper_reproducible --dataset zookeeper \\\n",
    "    --device cuda --random-seed 42 --max-epoch 25\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**Multiple Datasets:**\n",
    "\n",
    "The cell includes commented examples for all supported datasets. Simply uncomment the line for the dataset you want to train on. You can train multiple datasets sequentially or in separate runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vUxfxCrqAsVJ"
   },
   "outputs": [],
   "source": [
    "!python train.py --name hadoop --dataset hadoop --max-epoch 20\n",
    "# !python train.py --name spark --dataset spark --max-epoch 20\n",
    "# !python train.py --name zookeeper --dataset zookeeper --max-epoch 20\n",
    "# !python train.py --name bgl --dataset bgl --max-epoch 20\n",
    "# !python train.py --name windows --dataset windows --max-epoch 20\n",
    "# !python train.py --name casper-rw --dataset casper-rw --max-epoch 20\n",
    "# !python train.py --name dfrws-2009-jhuisi --dataset dfrws-2009-jhuisi --max-epoch 20\n",
    "# !python train.py --name dfrws-2009-nssal --dataset dfrws-2009-nssal --max-epoch 20\n",
    "# !python train.py --name honeynet-challenge7 --dataset honeynet-challenge7 --max-epoch 20\n",
    "# !python train.py --name honeynet-challenge5 --dataset honeynet-challenge5 --max-epoch 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z_YABxFQasbf"
   },
   "source": [
    "### Evaluate CoLog\n",
    "\n",
    "After training the CoLog model, we evaluate its performance on the test dataset to measure anomaly detection accuracy and generate comprehensive metrics reports.\n",
    "\n",
    "---\n",
    "\n",
    "**Why this is necessary:**\n",
    "- Assesses the trained model's performance on unseen test data\n",
    "- Generates detailed classification metrics (precision, recall, F1-score)\n",
    "- Creates visualization plots (confusion matrix, ROC curve, PR curve)\n",
    "- Supports ensemble evaluation using multiple checkpoints for improved accuracy\n",
    "- Enables cross-dataset generalizability testing\n",
    "\n",
    "---\n",
    "\n",
    "**Available Command-Line Arguments:**\n",
    "\n",
    "| Argument | Type | Default | Description |\n",
    "|----------|------|---------|-------------|\n",
    "| **Evaluation Configuration** |\n",
    "| `--checkpoints-path` | str | auto-generated | Path to checkpoints directory containing trained model files (best*.pkl) |\n",
    "| `--eval-sets` | list | `['test_set']` | List of evaluation sets to use: `valid_set`, `test_set`, or both |\n",
    "| `--ensemble` | flag | False | Enable ensemble predictions by averaging outputs from multiple checkpoints |\n",
    "| `--num-ckpts` | int | `1` | Number of checkpoints to use for evaluation/ensembling (newest first) |\n",
    "| **Model Configuration** |\n",
    "| `--name` | str | `CoLog` | Name identifier for the model (used for generalizability testing) |\n",
    "| `--dataset` | str | `hadoop` | Dataset name for evaluation (choices: hadoop, spark, bgl, windows, etc.) |\n",
    "| **Generalizability Testing** |\n",
    "| `--eval-generalizability` | flag | False | Enable cross-dataset generalization evaluation on unseen datasets |\n",
    "| **Reporting Options** |\n",
    "| `--plot-metrics` | flag | False | Generate full evaluation report with plots (confusion matrix, ROC, PR curves) |\n",
    "\n",
    "---\n",
    "\n",
    "**How Evaluation Works:**\n",
    "\n",
    "1. **Load Model Checkpoint(s)**: Loads best trained model(s) from `runs/<dataset>/models/`\n",
    "2. **Load Test Data**: Reads test set from ground truth directory\n",
    "3. **Generate Predictions**: Runs model inference on test sequences\n",
    "4. **Calculate Metrics**: Computes accuracy, precision, recall, F1-score, AUC, etc.\n",
    "5. **Visualization** (if `--plot-metrics`): Creates plots and saves as SVG/EPS files\n",
    "6. **Export Reports**: Saves classification reports to CSV files\n",
    "\n",
    "---\n",
    "\n",
    "**Evaluation Modes:**\n",
    "\n",
    "**1. Standard Evaluation (Single Checkpoint):**\n",
    "```bash\n",
    "!python test.py --checkpoints-path runs/hadoop/models/\n",
    "```\n",
    "- Uses the single best checkpoint\n",
    "- Fast evaluation\n",
    "- Good for quick performance checks\n",
    "\n",
    "**2. Ensemble Evaluation (Multiple Checkpoints):**\n",
    "```bash\n",
    "!python test.py --checkpoints-path runs/hadoop/models/ --ensemble --num-ckpts 5\n",
    "```\n",
    "- Averages predictions from top-5 checkpoints\n",
    "- Improves robustness and accuracy\n",
    "- Reduces variance from single-model predictions\n",
    "\n",
    "**3. Generalizability Testing (Cross-Dataset):**\n",
    "```bash\n",
    "# Train on hadoop, test on spark\n",
    "!python test.py --checkpoints-path runs/hadoop/models/ \\\n",
    "    --eval-generalizability --name spark --dataset spark\n",
    "```\n",
    "- Evaluates how well a model trained on one dataset performs on another\n",
    "- Tests transfer learning capabilities\n",
    "- Assesses model generalization\n",
    "\n",
    "**4. Full Report with Visualizations:**\n",
    "```bash\n",
    "!python test.py --checkpoints-path runs/hadoop/models/ --plot-metrics\n",
    "```\n",
    "- Generates all metrics plots\n",
    "- Creates confusion matrices (regular and normalized)\n",
    "- Produces ROC and Precision-Recall curves\n",
    "- Exports detailed CSV reports\n",
    "\n",
    "---\n",
    "\n",
    "**Output Files:**\n",
    "\n",
    "When using `--plot-metrics`, the following files are generated in the checkpoints directory:\n",
    "\n",
    "**Visualization Files:**\n",
    "- `confusion_matrix.svg` / `confusion_matrix.eps` - Visual confusion matrix\n",
    "- `confusion_matrix_normalized.svg` / `confusion_matrix_normalized.eps` - Normalized confusion matrix\n",
    "- `roc_curve.svg` / `roc_curve.eps` - Receiver Operating Characteristic curve\n",
    "- `precision_recall_curve.svg` / `precision_recall_curve.eps` - Precision-Recall curve\n",
    "\n",
    "**Report Files:**\n",
    "- `df_report.csv` - Standard classification report (precision, recall, F1-score per class)\n",
    "- `df_report_imb.csv` - Imbalanced classification metrics (additional metrics for imbalanced datasets)\n",
    "\n",
    "**Console Output:**\n",
    "- Accuracy, Precision, Recall, F1-Score\n",
    "- AUC-ROC, AUC-PR\n",
    "- Per-class performance metrics\n",
    "- Confusion matrix values\n",
    "\n",
    "---\n",
    "\n",
    "**Key Metrics Explained:**\n",
    "\n",
    "- **Accuracy**: Overall correctness of predictions\n",
    "- **Precision**: How many predicted anomalies are actually anomalies (fewer false positives)\n",
    "- **Recall**: How many actual anomalies are detected (fewer false negatives)\n",
    "- **F1-Score**: Harmonic mean of precision and recall (balanced metric)\n",
    "- **AUC-ROC**: Area Under ROC Curve (measures separability at all thresholds)\n",
    "- **AUC-PR**: Area Under Precision-Recall Curve (better for imbalanced datasets)\n",
    "\n",
    "---\n",
    "\n",
    "**Usage Examples:**\n",
    "\n",
    "```bash\n",
    "# Basic evaluation on test set\n",
    "!python test.py --checkpoints-path runs/hadoop/models/\n",
    "\n",
    "# Evaluation with full metrics visualization\n",
    "!python test.py --checkpoints-path runs/hadoop/models/ --plot-metrics\n",
    "\n",
    "# Ensemble evaluation with top 3 checkpoints\n",
    "!python test.py --checkpoints-path runs/spark/models/ --ensemble --num-ckpts 3 --plot-metrics\n",
    "\n",
    "# Evaluate on both validation and test sets\n",
    "!python test.py --checkpoints-path runs/zookeeper/models/ \\\n",
    "    --eval-sets valid_set test_set --plot-metrics\n",
    "\n",
    "# Cross-dataset generalizability (trained on BGL, tested on Hadoop)\n",
    "!python test.py --checkpoints-path runs/bgl/models/ \\\n",
    "    --eval-generalizability --name hadoop --dataset hadoop \\\n",
    "    --plot-metrics\n",
    "\n",
    "# Auto-generated checkpoints path from dataset name\n",
    "!python test.py --dataset hadoop --plot-metrics\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**Evaluation Tips:**\n",
    "\n",
    "- Always use `--plot-metrics` for comprehensive analysis and publication-ready figures\n",
    "- Use `--ensemble` with `--num-ckpts 3-5` for more robust predictions\n",
    "- For imbalanced datasets, focus on F1-score and AUC-PR rather than just accuracy\n",
    "- Test generalizability by evaluating on different datasets to assess model robustness\n",
    "- Compare performance on validation vs test sets to detect overfitting\n",
    "\n",
    "---\n",
    "\n",
    "**Multiple Datasets:**\n",
    "\n",
    "The cell includes commented examples for all supported datasets. Simply uncomment the line for the dataset you want to evaluate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vrRCmXaDDeBL"
   },
   "outputs": [],
   "source": [
    "!python test.py --checkpoints-path runs/hadoop/models/ --plot-metrics\n",
    "# !python test.py --checkpoints-path runs/spark/models/ --plot-metrics\n",
    "# !python test.py --checkpoints-path runs/zookeeper/models/ --plot-metrics\n",
    "# !python test.py --checkpoints-path runs/bgl/models/ --plot-metrics\n",
    "# !python test.py --checkpoints-path runs/windows/models/ --plot-metrics\n",
    "# !python test.py --checkpoints-path runs/casper-rw/models/ --plot-metrics\n",
    "# !python test.py --checkpoints-path runs/dfrws-2009-jhuisi/models/ --plot-metrics\n",
    "# !python test.py --checkpoints-path runs/dfrws-2009-nssal/models/ --plot-metrics\n",
    "# !python test.py --checkpoints-path runs/honeynet-challenge7/models/ --plot-metrics\n",
    "# !python test.py --checkpoints-path runs/honeynet-challenge5/models/ --plot-metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a88Tnj_yasbg"
   },
   "source": [
    "### Run TensorBoard for Hyperparameter Tuning Results\n",
    "\n",
    "The following cells allow you to visualize the hyperparameter tuning results using TensorBoard:\n",
    "\n",
    "1. **Load TensorBoard Extension**: The first cell loads the TensorBoard extension into the notebook\n",
    "2. **Launch TensorBoard**: The second cell starts TensorBoard and points it to the tuning results directory\n",
    "\n",
    "**Instructions**:\n",
    "- Replace `tuned_folder_path` with the actual path to your hyperparameter tuning logs\n",
    "- TensorBoard will display metrics, parameter comparisons, and training progress for all tuning trials\n",
    "- You can compare different hyperparameter configurations to find the optimal settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6nyBijrhM2ip"
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jk3TVjABW-Mk"
   },
   "outputs": [],
   "source": [
    "%tensorboard --logdir tuned_folder_path"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
